{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Semantic Analysis\n",
    "- Fine tune the embedding model: https://sbert.net/docs/sentence_transformer/training_overview.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='726' max='726' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [726/726 01:54, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.002500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=726, training_loss=0.0017738862081171725, metrics={'train_runtime': 114.9419, 'train_samples_per_second': 50.504, 'train_steps_per_second': 6.316, 'total_flos': 0.0, 'train_loss': 0.0017738862081171725, 'epoch': 3.0})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer, SentenceTransformerTrainer, losses\n",
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "\n",
    "user_prompts = pd.read_csv('./datasets/user_prompts.csv')\n",
    "system_prompts = pd.read_csv('./datasets/system_prompts.csv')\n",
    "\n",
    "model = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "system_prompts_list = []\n",
    "user_prompts_list = []\n",
    "is_injected_list = []\n",
    "\n",
    "system_prompts_dict = {row['id']: row['system_prompt'] for _, row in system_prompts.iloc[:100].iterrows()}\n",
    "user_prompts_by_system = user_prompts.groupby('system_prompt_id')\n",
    "\n",
    "for system_id, system_prompt in system_prompts_dict.items():\n",
    "    if system_id in user_prompts_by_system.groups:\n",
    "        matching_user_prompts = user_prompts_by_system.get_group(system_id)\n",
    "        system_prompts_list.extend([system_prompt] * len(matching_user_prompts))\n",
    "        user_prompts_list.extend(matching_user_prompts['user_input'].tolist())\n",
    "        is_injected_list.extend(matching_user_prompts['is_injection'].tolist())\n",
    "\n",
    "train_dataset = Dataset.from_dict({\n",
    "    \"sentence1\": system_prompts_list,\n",
    "    \"sentence2\": user_prompts_list,\n",
    "    \"label\": is_injected_list,\n",
    "})\n",
    "\n",
    "loss = losses.ContrastiveLoss(model)\n",
    "\n",
    "trainer = SentenceTransformerTrainer(\n",
    "    model=model,\n",
    "    train_dataset=train_dataset,\n",
    "    loss=loss,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Results on Test Set:\n",
      "Number of system prompts tested: 20\n",
      "Number of user prompts tested: 390\n",
      "Accuracy: 0.9615\n",
      "Precision: 0.9524\n",
      "Recall: 1.0000\n",
      "F1 Score: 0.9756\n"
     ]
    }
   ],
   "source": [
    "# Select 20 system prompts that weren't in training\n",
    "test_system_prompts = system_prompts.iloc[100:120]  # Get 20 prompts after the first 100 used in training\n",
    "test_system_ids = test_system_prompts['id'].tolist()\n",
    "\n",
    "# Get corresponding user prompts\n",
    "test_user_prompts_df = user_prompts[user_prompts['system_prompt_id'].isin(test_system_ids)]\n",
    "\n",
    "# Create lists for evaluation\n",
    "test_system_prompts_list = []\n",
    "test_user_prompts_list = []\n",
    "test_is_injected_list = []\n",
    "\n",
    "# Group user prompts by system prompt\n",
    "for _, system_row in test_system_prompts.iterrows():\n",
    "    matching_users = test_user_prompts_df[test_user_prompts_df['system_prompt_id'] == system_row['id']]\n",
    "    test_system_prompts_list.extend([system_row['system_prompt']] * len(matching_users))\n",
    "    test_user_prompts_list.extend(matching_users['user_input'].tolist())\n",
    "    test_is_injected_list.extend(matching_users['is_injection'].tolist())\n",
    "\n",
    "# Encode test prompts\n",
    "test_system_embeddings = model.encode(test_system_prompts_list)\n",
    "test_user_embeddings = model.encode(test_user_prompts_list)\n",
    "\n",
    "# Calculate cosine similarities\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "similarities = cosine_similarity(test_system_embeddings, test_user_embeddings)\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import numpy as np\n",
    "\n",
    "# Convert similarities to binary predictions\n",
    "threshold = 0.5\n",
    "predictions = (similarities.diagonal() > threshold).astype(int)\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy = accuracy_score(test_is_injected_list, predictions)\n",
    "precision = precision_score(test_is_injected_list, predictions)\n",
    "recall = recall_score(test_is_injected_list, predictions)\n",
    "f1 = f1_score(test_is_injected_list, predictions)\n",
    "\n",
    "print(f\"Evaluation Results on Test Set:\")\n",
    "print(f\"Number of system prompts tested: {len(test_system_prompts)}\")\n",
    "print(f\"Number of user prompts tested: {len(test_user_prompts_list)}\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\") \n",
    "print(f\"F1 Score: {f1:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "from models.utils import get_training_and_validation_splits\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from setfit import SetFitModel, TrainingArguments, Trainer\n",
    "import torch\n",
    "\n",
    "class SetFitPromptEmbeddingTrainer:\n",
    "    def __init__(self, model_name):\n",
    "        self.device = \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "        self.model = SetFitModel.from_pretrained(model_name).to(self.device)\n",
    "        self.trainer = None\n",
    "        \n",
    "    def prepare_dataset(self, system_prompts_df, user_prompts_df):\n",
    "        system_prompts_list = system_prompts_df[\"system_prompt\"].tolist()\n",
    "        user_prompts_list = user_prompts_df[\"user_input\"].tolist()\n",
    "        is_injected_list = user_prompts_df[\"is_injection\"].tolist()\n",
    "        \n",
    "        text_pairs = [\n",
    "            f\"System: {system_prompt} \\n User: {user_prompt}\"\n",
    "            for system_prompt, user_prompt in zip(system_prompts_list, user_prompts_list)\n",
    "        ]\n",
    "        \n",
    "        dataset = Dataset.from_dict({\n",
    "            \"text\": text_pairs,\n",
    "            \"label\": is_injected_list,\n",
    "        })\n",
    "        \n",
    "        return dataset\n",
    "        \n",
    "    def train(self, epochs=3, iterations=20):\n",
    "        (train_system_prompts, train_user_prompts), (val_system_prompts, val_user_prompts) = get_training_and_validation_splits(total_size=10)\n",
    "\n",
    "        train_dataset = self.prepare_dataset(train_system_prompts, train_user_prompts)\n",
    "        val_dataset = self.prepare_dataset(val_system_prompts, val_user_prompts)\n",
    "        \n",
    "        args = TrainingArguments(\n",
    "            num_epochs=epochs,\n",
    "            num_iterations=iterations,\n",
    "        )\n",
    "        \n",
    "        self.trainer = Trainer(\n",
    "            model=self.model,\n",
    "            args=args,\n",
    "            train_dataset=train_dataset,\n",
    "            eval_dataset=val_dataset,\n",
    "            metric=\"f1\"\n",
    "        )\n",
    "        \n",
    "        self.trainer.train()\n",
    "        self.model.save_pretrained(\"./saved_models/setfit_model\")\n",
    "        \n",
    "    def evaluate(self):\n",
    "        if self.trainer is None:\n",
    "            raise ValueError(\"Model must be trained before evaluation\")\n",
    "            \n",
    "        (_, _), (val_system_prompts, val_user_prompts) = get_training_and_validation_splits()\n",
    "        val_dataset = self.prepare_dataset(val_system_prompts, val_user_prompts)\n",
    "        \n",
    "        predictions = self.model.predict(val_dataset[\"text\"])\n",
    "        \n",
    "        accuracy = accuracy_score(val_user_prompts[\"is_injection\"].tolist(), predictions)\n",
    "        precision = precision_score(val_user_prompts[\"is_injection\"].tolist(), predictions)\n",
    "        recall = recall_score(val_user_prompts[\"is_injection\"].tolist(), predictions)\n",
    "        f1 = f1_score(val_user_prompts[\"is_injection\"].tolist(), predictions)\n",
    "        \n",
    "        results = {\n",
    "            \"num_system_prompts\": len(val_system_prompts),\n",
    "            \"num_user_prompts\": len(val_user_prompts),\n",
    "            \"accuracy\": accuracy,\n",
    "            \"precision\": precision,\n",
    "            \"recall\": recall,\n",
    "            \"f1\": f1,\n",
    "        }\n",
    "        \n",
    "        return results\n",
    "        \n",
    "    def get_model(self):\n",
    "        return self.model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "model_head.pkl not found on HuggingFace Hub, initialising classification head with random weights. You should TRAIN this model on a downstream task to use it for predictions and inference.\n",
      "Map: 100%|██████████| 160/160 [00:00<00:00, 26041.47 examples/s]\n",
      "***** Running training *****\n",
      "  Num unique pairs = 6400\n",
      "  Batch size = 16\n",
      "  Num epochs = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1200' max='1200' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1200/1200 06:09, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.293400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.268100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.245900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.191300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.172500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.135100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.158700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.146200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.148600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.148600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.146100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.139000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.137000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>0.141300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.144400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>0.133200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.140800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>0.143800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.137800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>0.136000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.122900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1050</td>\n",
       "      <td>0.126300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.148400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1150</td>\n",
       "      <td>0.135200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.141200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation Results:\n",
      "num_system_prompts: 3254\n",
      "num_user_prompts: 3254\n",
      "accuracy: 0.8976644130301168\n",
      "precision: 0.9066220238095238\n",
      "recall: 0.9674473997618103\n",
      "f1: 0.9360476281928174\n"
     ]
    }
   ],
   "source": [
    "# Create SetFit trainer with default model\n",
    "trainer = SetFitPromptEmbeddingTrainer(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "# Train the model with default parameters (3 epochs, 20 iterations)\n",
    "trainer.train()\n",
    "\n",
    "# Evaluate the model and print results\n",
    "eval_results = trainer.evaluate()\n",
    "print(\"\\nEvaluation Results:\")\n",
    "for metric, value in eval_results.items():\n",
    "    print(f\"{metric}: {value}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
