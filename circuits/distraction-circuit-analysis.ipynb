{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kevinlu/Code/prompt-helmet/venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch as t\n",
    "\n",
    "from auto_circuit.data import load_datasets_from_json\n",
    "from auto_circuit.experiment_utils import load_tl_model\n",
    "from auto_circuit.prune_algos.mask_gradient import mask_gradient_prune_scores\n",
    "from auto_circuit.types import PruneScores\n",
    "from auto_circuit.utils.graph_utils import patchable_model\n",
    "from auto_circuit.utils.misc import repo_path_to_abs_path\n",
    "from auto_circuit.visualize import draw_seq_graph\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "WARNING:root:You are not using LayerNorm, so the writing weights can't be centered! Skipping\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model Qwen/Qwen2.5-1.5B into HookedTransformer\n"
     ]
    }
   ],
   "source": [
    "device = t.device(\"cuda\" if t.cuda.is_available() else \"cpu\")\n",
    "model = load_tl_model(\"Qwen/Qwen2.5-1.5B\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "path = Path(\"./clean_corrupt_prompts.json\")\n",
    "train_loader, test_loader = load_datasets_from_json(\n",
    "    model=model,\n",
    "    path=path,\n",
    "    device=device,\n",
    "    prepend_bos=True,\n",
    "    batch_size=1,\n",
    "    train_test_size=(56, 56),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Model is already patchable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mpatchable_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfactorized\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mslice_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlast_seq\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mseparate_qkv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Code/prompt-helmet/venv/lib/python3.12/site-packages/auto_circuit/utils/graph_utils.py:69\u001b[0m, in \u001b[0;36mpatchable_model\u001b[0;34m(model, factorized, slice_output, seq_len, separate_qkv, kv_caches, device)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mpatchable_model\u001b[39m(\n\u001b[1;32m     36\u001b[0m     model: t\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mModule,\n\u001b[1;32m     37\u001b[0m     factorized: \u001b[38;5;28mbool\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     42\u001b[0m     device: t\u001b[38;5;241m.\u001b[39mdevice \u001b[38;5;241m=\u001b[39m t\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m     43\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m PatchableModel:\n\u001b[1;32m     44\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;124;03m    Wrap a model and inject [`PatchWrapper`][auto_circuit.types.PatchWrapper]s into the\u001b[39;00m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;124;03m    node modules to enable patching.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;124;03m        This function modifies the model, it does not return a new model.\u001b[39;00m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 69\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(model, PatchableModel), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel is already patchable\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     70\u001b[0m     nodes, srcs, dests, edge_dict, edges, seq_dim, seq_len \u001b[38;5;241m=\u001b[39m graph_edges(\n\u001b[1;32m     71\u001b[0m         model, factorized, separate_qkv, seq_len\n\u001b[1;32m     72\u001b[0m     )\n\u001b[1;32m     73\u001b[0m     wrappers, src_wrappers, dest_wrappers \u001b[38;5;241m=\u001b[39m make_model_patchable(\n\u001b[1;32m     74\u001b[0m         model, factorized, srcs, nodes, device, seq_len, seq_dim\n\u001b[1;32m     75\u001b[0m     )\n",
      "\u001b[0;31mAssertionError\u001b[0m: Model is already patchable"
     ]
    }
   ],
   "source": [
    "model = patchable_model(\n",
    "    model,\n",
    "    factorized=True,\n",
    "    slice_output=\"last_seq\",\n",
    "    separate_qkv=True,\n",
    "    device=device,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sample: 0          | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (2) must match the size of tensor b (12) at non-singleton dimension 2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m attribution_scores: PruneScores \u001b[38;5;241m=\u001b[39m \u001b[43mmask_gradient_prune_scores\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdataloader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mofficial_edges\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_function\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogit\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer_function\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mavg_diff\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmask_val\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Code/prompt-helmet/venv/lib/python3.12/site-packages/auto_circuit/prune_algos/mask_gradient.py:86\u001b[0m, in \u001b[0;36mmask_gradient_prune_scores\u001b[0;34m(model, dataloader, official_edges, grad_function, answer_function, mask_val, integrated_grad_samples, ablation_type, clean_corrupt)\u001b[0m\n\u001b[1;32m     84\u001b[0m patch_src_outs \u001b[38;5;241m=\u001b[39m src_outs[batch\u001b[38;5;241m.\u001b[39mkey]\u001b[38;5;241m.\u001b[39mclone()\u001b[38;5;241m.\u001b[39mdetach()\n\u001b[1;32m     85\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m patch_mode(model, patch_src_outs):\n\u001b[0;32m---> 86\u001b[0m     logits \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclean\u001b[49m\u001b[43m)\u001b[49m[out_slice]\n\u001b[1;32m     87\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m grad_function \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlogit\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m     88\u001b[0m         token_vals \u001b[38;5;241m=\u001b[39m logits\n",
      "File \u001b[0;32m~/Code/prompt-helmet/venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Code/prompt-helmet/venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/Code/prompt-helmet/venv/lib/python3.12/site-packages/auto_circuit/utils/patchable_model.py:139\u001b[0m, in \u001b[0;36mPatchableModel.forward\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    135\u001b[0m \u001b[38;5;124;03mWrapper around the forward method of the wrapped model. If `kv_caches` is not\u001b[39;00m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;124;03m`None`, the KV cache is passed to the wrapped model as a keyword argument.\u001b[39;00m\n\u001b[1;32m    137\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    138\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkv_caches \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpast_kv_cache\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m kwargs:\n\u001b[0;32m--> 139\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrapped_model\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    140\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    141\u001b[0m     batch_size \u001b[38;5;241m=\u001b[39m args[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/Code/prompt-helmet/venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Code/prompt-helmet/venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/Code/prompt-helmet/venv/lib/python3.12/site-packages/transformer_lens/HookedTransformer.py:612\u001b[0m, in \u001b[0;36mHookedTransformer.forward\u001b[0;34m(self, input, return_type, loss_per_token, prepend_bos, padding_side, start_at_layer, tokens, shortformer_pos_embed, attention_mask, stop_at_layer, past_kv_cache)\u001b[0m\n\u001b[1;32m    607\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m shortformer_pos_embed \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    608\u001b[0m         shortformer_pos_embed \u001b[38;5;241m=\u001b[39m shortformer_pos_embed\u001b[38;5;241m.\u001b[39mto(\n\u001b[1;32m    609\u001b[0m             devices\u001b[38;5;241m.\u001b[39mget_device_for_block_index(i, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcfg)\n\u001b[1;32m    610\u001b[0m         )\n\u001b[0;32m--> 612\u001b[0m     residual \u001b[38;5;241m=\u001b[39m \u001b[43mblock\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    613\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresidual\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    614\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Cache contains a list of HookedTransformerKeyValueCache objects, one for each\u001b[39;49;00m\n\u001b[1;32m    615\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# block\u001b[39;49;00m\n\u001b[1;32m    616\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_kv_cache_entry\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_kv_cache\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpast_kv_cache\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    617\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshortformer_pos_embed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshortformer_pos_embed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    618\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    619\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# [batch, pos, d_model]\u001b[39;00m\n\u001b[1;32m    621\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m stop_at_layer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    622\u001b[0m     \u001b[38;5;66;03m# When we stop at an early layer, we end here rather than doing further computation\u001b[39;00m\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m residual\n",
      "File \u001b[0;32m~/Code/prompt-helmet/venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Code/prompt-helmet/venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/Code/prompt-helmet/venv/lib/python3.12/site-packages/transformer_lens/components/transformer_block.py:145\u001b[0m, in \u001b[0;36mTransformerBlock.forward\u001b[0;34m(self, resid_pre, shortformer_pos_embed, past_kv_cache_entry, attention_mask)\u001b[0m\n\u001b[1;32m    136\u001b[0m     n_kv_heads \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    137\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcfg\u001b[38;5;241m.\u001b[39mn_key_value_heads\n\u001b[1;32m    138\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcfg\u001b[38;5;241m.\u001b[39mn_key_value_heads \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    139\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcfg\u001b[38;5;241m.\u001b[39mungroup_grouped_query_attention\n\u001b[1;32m    140\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcfg\u001b[38;5;241m.\u001b[39mn_heads\n\u001b[1;32m    141\u001b[0m     )\n\u001b[1;32m    142\u001b[0m     query_input \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhook_q_input(\n\u001b[1;32m    143\u001b[0m         repeat_along_head_dimension(resid_pre, n_heads\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcfg\u001b[38;5;241m.\u001b[39mn_heads)\n\u001b[1;32m    144\u001b[0m     )\n\u001b[0;32m--> 145\u001b[0m     key_input \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhook_k_input\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    146\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrepeat_along_head_dimension\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresid_pre\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_heads\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_kv_heads\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    147\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    148\u001b[0m     value_input \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhook_v_input(\n\u001b[1;32m    149\u001b[0m         repeat_along_head_dimension(resid_pre, n_heads\u001b[38;5;241m=\u001b[39mn_kv_heads)\n\u001b[1;32m    150\u001b[0m     )\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/Code/prompt-helmet/venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Code/prompt-helmet/venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/Code/prompt-helmet/venv/lib/python3.12/site-packages/auto_circuit/utils/patch_wrapper.py:148\u001b[0m, in \u001b[0;36mPatchWrapperImpl.forward\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    146\u001b[0m     ein_pre \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbatch_str\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mseq_str\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhead_str\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m src, src batch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdims\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m ...\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    147\u001b[0m     ein_post \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdims\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhead_str\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m ...\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 148\u001b[0m     \u001b[43marg_0\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43meinsum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43md\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mein_pre\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m -> \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mein_post\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Add mask times diff\u001b[39;00m\n\u001b[1;32m    150\u001b[0m new_args \u001b[38;5;241m=\u001b[39m (arg_0,) \u001b[38;5;241m+\u001b[39m args[\u001b[38;5;241m1\u001b[39m:]\n\u001b[1;32m    151\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodule(\u001b[38;5;241m*\u001b[39mnew_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (2) must match the size of tensor b (12) at non-singleton dimension 2"
     ]
    }
   ],
   "source": [
    "attribution_scores: PruneScores = mask_gradient_prune_scores(\n",
    "    model=model,\n",
    "    dataloader=train_loader,\n",
    "    official_edges=None,\n",
    "    grad_function=\"logit\",\n",
    "    answer_function=\"avg_diff\",\n",
    "    mask_val=0.0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "arrangement": "perpendicular",
         "domain": {
          "y": [
           0,
           1
          ]
         },
         "link": {
          "arrowlen": 25,
          "color": [
           "rgba(0,0,255,0.3)",
           "rgba(255,0,0,0.3)",
           "rgba(0,0,255,0.3)",
           "rgba(0,0,255,0.3)",
           "rgba(255,0,0,0.3)",
           "rgba(0,0,255,0.3)",
           "rgba(0,0,255,0.3)",
           "rgba(0,0,255,0.3)",
           "rgba(0,0,255,0.3)",
           "rgba(255,0,0,0.3)",
           "rgba(255,0,0,0.3)",
           "rgba(255,0,0,0.3)",
           "rgba(255,0,0,0.3)",
           "rgba(255,0,0,0.3)",
           "rgba(0,0,255,0.3)",
           "rgba(255,0,0,0.3)",
           "rgba(0,0,255,0.3)",
           "rgba(255,0,0,0.3)",
           "rgba(255,0,0,0.3)",
           "rgba(255,0,0,0.3)",
           "rgba(0,255,0,0.0)",
           "rgba(0,255,0,0.0)",
           "rgba(0,255,0,0.0)",
           "rgba(0,255,0,0.0)",
           "rgba(0,255,0,0.0)",
           "rgba(0,255,0,0.0)",
           "rgba(0,255,0,0.0)",
           "rgba(0,255,0,0.0)",
           "rgba(0,255,0,0.0)",
           "rgba(0,255,0,0.0)",
           "rgba(0,255,0,0.0)",
           "rgba(0,255,0,0.0)",
           "rgba(0,255,0,0.0)",
           "rgba(0,255,0,0.0)",
           "rgba(0,255,0,0.0)",
           "rgba(0,255,0,0.0)",
           "rgba(0,255,0,0.0)",
           "rgba(0,255,0,0.0)",
           "rgba(0,255,0,0.0)",
           "rgba(0,255,0,0.0)",
           "rgba(0,255,0,0.0)",
           "rgba(0,255,0,0.0)",
           "rgba(0,255,0,0.0)",
           "rgba(0,255,0,0.0)",
           "rgba(0,255,0,0.0)",
           "rgba(0,255,0,0.0)",
           "rgba(0,255,0,0.0)",
           "rgba(0,255,0,0.0)",
           "rgba(0,255,0,0.0)",
           "rgba(0,255,0,0.0)",
           "rgba(0,255,0,0.0)",
           "rgba(0,255,0,0.0)",
           "rgba(0,255,0,0.0)",
           "rgba(0,255,0,0.0)",
           "rgba(0,255,0,0.0)",
           "rgba(0,255,0,0.0)",
           "rgba(0,255,0,0.0)",
           "rgba(0,255,0,0.0)",
           "rgba(0,255,0,0.0)",
           "rgba(0,255,0,0.0)",
           "rgba(0,255,0,0.0)",
           "rgba(0,255,0,0.0)",
           "rgba(0,255,0,0.0)",
           "rgba(0,255,0,0.0)",
           "rgba(0,255,0,0.0)",
           "rgba(0,255,0,0.0)",
           "rgba(0,255,0,0.0)",
           "rgba(0,255,0,0.0)",
           "rgba(0,255,0,0.0)",
           "rgba(0,255,0,0.0)",
           "rgba(0,255,0,0.0)",
           "rgba(0,255,0,0.0)",
           "rgba(0,255,0,0.0)",
           "rgba(0,255,0,0.0)",
           "rgba(0,255,0,0.0)",
           "rgba(0,255,0,0.0)",
           "rgba(0,255,0,0.0)",
           "rgba(0,255,0,0.0)",
           "rgba(0,255,0,0.0)",
           "rgba(0,255,0,0.0)",
           "rgba(0,255,0,0.0)",
           "rgba(0,255,0,0.0)",
           "rgba(0,255,0,0.0)",
           "rgba(0,255,0,0.0)",
           "rgba(0,255,0,0.0)",
           "rgba(0,255,0,0.0)",
           "rgba(0,255,0,0.0)",
           "rgba(0,255,0,0.0)",
           "rgba(0,255,0,0.0)",
           "rgba(0,255,0,0.0)",
           "rgba(0,255,0,0.0)",
           "rgba(0,255,0,0.0)",
           "rgba(0,255,0,0.0)",
           "rgba(0,255,0,0.0)",
           "rgba(0,255,0,0.0)",
           "rgba(0,255,0,0.0)",
           "rgba(0,255,0,0.0)",
           "rgba(0,255,0,0.0)",
           "rgba(0,255,0,0.0)",
           "rgba(0,255,0,0.0)",
           "rgba(0,255,0,0.0)",
           "rgba(0,255,0,0.0)",
           "rgba(0,255,0,0.0)",
           "rgba(0,255,0,0.0)",
           "rgba(0,255,0,0.0)",
           "rgba(0,255,0,0.0)",
           "rgba(0,255,0,0.0)",
           "rgba(0,255,0,0.0)",
           "rgba(0,255,0,0.0)",
           "rgba(0,255,0,0.0)",
           "rgba(0,255,0,0.0)",
           "rgba(0,255,0,0.0)",
           "rgba(0,255,0,0.0)",
           "rgba(0,255,0,0.0)",
           "rgba(0,255,0,0.0)",
           "rgba(0,255,0,0.0)",
           "rgba(0,255,0,0.0)",
           "rgba(0,255,0,0.0)"
          ],
          "label": [
           "A10.7->A11.10.Q<br>None<br>11.82",
           "A9.9->A10.7.Q<br>None<br>-5.16",
           "A9.6->Resid End<br>None<br>10.83",
           "A3.0->A5.9.Q<br>None<br>6.36",
           "A10.7->Resid End<br>None<br>-19.49",
           "Resid Start->A0.10.Q<br>None<br>3.93",
           "A10.1->Resid End<br>None<br>3.63",
           "Resid Start->A0.10.K<br>None<br>3.85",
           "A9.9->Resid End<br>None<br>27.00",
           "A9.9->A11.10.Q<br>None<br>-11.43",
           "A11.10->Resid End<br>None<br>-7.83",
           "A11.2->Resid End<br>None<br>-3.85",
           "MLP 0->A11.10.K<br>None<br>-4.58",
           "Resid Start->MLP 0<br>None<br>-21.64",
           "A10.0->Resid End<br>None<br>5.97",
           "A9.6->A11.10.Q<br>None<br>-4.19",
           "MLP 0->MLP 1<br>None<br>4.77",
           "A3.0->MLP 4<br>None<br>-5.59",
           "MLP 0->MLP 3<br>None<br>-4.13",
           "MLP 3->A5.9.Q<br>None<br>-3.89",
           "",
           "",
           "",
           "",
           "",
           "",
           "",
           "",
           "",
           "",
           "",
           "",
           "",
           "",
           "",
           "",
           "",
           "",
           "",
           "",
           "",
           "",
           "",
           "",
           "",
           "",
           "",
           "",
           "",
           "",
           "",
           "",
           "",
           "",
           "",
           "",
           "",
           "",
           "",
           "",
           "",
           "",
           "",
           "",
           "",
           "",
           "",
           "",
           "",
           "",
           "",
           "",
           "",
           "",
           "",
           "",
           "",
           "",
           "",
           "",
           "",
           "",
           "",
           "",
           "",
           "",
           "",
           "",
           "",
           "",
           "",
           "",
           "",
           "",
           "",
           "",
           "",
           "",
           "",
           "",
           "",
           "",
           "",
           "",
           "",
           "",
           "",
           "",
           "",
           "",
           "",
           "",
           "",
           "",
           "",
           "",
           "",
           ""
          ],
          "source": [
           41,
           6,
           28,
           35,
           41,
           104,
           31,
           104,
           6,
           6,
           128,
           85,
           99,
           104,
           88,
           28,
           99,
           35,
           99,
           96,
           104,
           104,
           104,
           104,
           104,
           141,
           141,
           141,
           141,
           141,
           141,
           99,
           99,
           99,
           99,
           99,
           19,
           19,
           92,
           92,
           8,
           8,
           59,
           59,
           59,
           35,
           35,
           35,
           35,
           96,
           96,
           96,
           12,
           12,
           131,
           131,
           131,
           51,
           51,
           51,
           157,
           157,
           1,
           1,
           95,
           95,
           25,
           25,
           137,
           137,
           63,
           63,
           18,
           18,
           18,
           18,
           18,
           18,
           6,
           28,
           6,
           6,
           28,
           6,
           155,
           155,
           155,
           155,
           155,
           155,
           41,
           41,
           41,
           31,
           88,
           41,
           147,
           147,
           147,
           147,
           147,
           147,
           147,
           128,
           128,
           128,
           85,
           128,
           128,
           128,
           65,
           65,
           65,
           65,
           65,
           65,
           65,
           65
          ],
          "target": [
           128,
           41,
           154,
           51,
           154,
           141,
           154,
           141,
           154,
           128,
           154,
           154,
           128,
           99,
           154,
           128,
           92,
           131,
           96,
           51,
           141,
           141,
           141,
           141,
           141,
           99,
           99,
           99,
           99,
           99,
           99,
           19,
           19,
           19,
           19,
           19,
           92,
           92,
           8,
           8,
           59,
           59,
           35,
           35,
           35,
           96,
           96,
           96,
           96,
           12,
           12,
           12,
           131,
           131,
           51,
           51,
           51,
           157,
           157,
           157,
           1,
           1,
           95,
           95,
           25,
           25,
           137,
           137,
           63,
           63,
           18,
           18,
           6,
           6,
           28,
           6,
           6,
           28,
           155,
           155,
           155,
           155,
           155,
           155,
           41,
           41,
           41,
           41,
           31,
           88,
           147,
           147,
           147,
           147,
           147,
           147,
           128,
           128,
           128,
           128,
           85,
           128,
           128,
           65,
           65,
           65,
           65,
           65,
           65,
           65,
           154,
           154,
           154,
           154,
           154,
           154,
           154,
           154
          ],
          "value": [
           11.823381423950195,
           5.156394958496094,
           10.826767921447754,
           6.3575215339660645,
           19.49233627319336,
           3.930436134338379,
           3.6340761184692383,
           3.847560405731201,
           27.004131317138672,
           11.430303573608398,
           7.826684951782227,
           3.847963571548462,
           4.582206726074219,
           21.635541915893555,
           5.968253135681152,
           4.188978672027588,
           4.769560813903809,
           5.590115547180176,
           4.1276397705078125,
           3.8889758586883545,
           0.000001,
           0.000001,
           0.000001,
           0.000001,
           0.000001,
           0.000001,
           0.000001,
           0.000001,
           0.000001,
           0.000001,
           0.000001,
           0.000001,
           0.000001,
           0.000001,
           0.000001,
           0.000001,
           0.000001,
           0.000001,
           0.000001,
           0.000001,
           0.000001,
           0.000001,
           0.000001,
           0.000001,
           0.000001,
           0.000001,
           0.000001,
           0.000001,
           0.000001,
           0.000001,
           0.000001,
           0.000001,
           0.000001,
           0.000001,
           0.000001,
           0.000001,
           0.000001,
           0.000001,
           0.000001,
           0.000001,
           0.000001,
           0.000001,
           0.000001,
           0.000001,
           0.000001,
           0.000001,
           0.000001,
           0.000001,
           0.000001,
           0.000001,
           0.000001,
           0.000001,
           0.000001,
           0.000001,
           0.000001,
           0.000001,
           0.000001,
           0.000001,
           0.000001,
           0.000001,
           0.000001,
           0.000001,
           0.000001,
           0.000001,
           0.000001,
           0.000001,
           0.000001,
           0.000001,
           0.000001,
           0.000001,
           0.000001,
           0.000001,
           0.000001,
           0.000001,
           0.000001,
           0.000001,
           0.000001,
           0.000001,
           0.000001,
           0.000001,
           0.000001,
           0.000001,
           0.000001,
           0.000001,
           0.000001,
           0.000001,
           0.000001,
           0.000001,
           0.000001,
           0.000001,
           0.000001,
           0.000001,
           0.000001,
           0.000001,
           0.000001,
           0.000001,
           0.000001,
           0.000001
          ]
         },
         "node": {
          "color": [
           "rgba(0,0,0,0.0)",
           "rgba(0,0,0,0.0)",
           "rgba(0,0,0,0.0)",
           "rgba(0,0,0,0.0)",
           "rgba(0,0,0,0.0)",
           "rgba(0,0,0,0.0)",
           "rgb(55, 126, 184)",
           "rgba(0,0,0,0.0)",
           "rgba(0,0,0,0.0)",
           "rgba(0,0,0,0.0)",
           "rgba(0,0,0,0.0)",
           "rgba(0,0,0,0.0)",
           "rgba(0,0,0,0.0)",
           "rgba(0,0,0,0.0)",
           "rgba(0,0,0,0.0)",
           "rgba(0,0,0,0.0)",
           "rgba(0,0,0,0.0)",
           "rgba(0,0,0,0.0)",
           "rgba(0,0,0,0.0)",
           "rgba(0,0,0,0.0)",
           "rgba(0,0,0,0.0)",
           "rgba(0,0,0,0.0)",
           "rgba(0,0,0,0.0)",
           "rgba(0,0,0,0.0)",
           "rgba(0,0,0,0.0)",
           "rgba(0,0,0,0.0)",
           "rgba(0,0,0,0.0)",
           "rgba(0,0,0,0.0)",
           "rgb(166, 86, 40)",
           "rgba(0,0,0,0.0)",
           "rgba(0,0,0,0.0)",
           "rgb(166, 86, 40)",
           "rgba(0,0,0,0.0)",
           "rgba(0,0,0,0.0)",
           "rgba(0,0,0,0.0)",
           "rgb(222, 222, 0)",
           "rgba(0,0,0,0.0)",
           "rgba(0,0,0,0.0)",
           "rgba(0,0,0,0.0)",
           "rgba(0,0,0,0.0)",
           "rgba(0,0,0,0.0)",
           "rgb(228, 26, 28)",
           "rgba(0,0,0,0.0)",
           "rgba(0,0,0,0.0)",
           "rgba(0,0,0,0.0)",
           "rgba(0,0,0,0.0)",
           "rgba(0,0,0,0.0)",
           "rgba(0,0,0,0.0)",
           "rgba(0,0,0,0.0)",
           "rgba(0,0,0,0.0)",
           "rgba(0,0,0,0.0)",
           "rgb(255, 127, 0)",
           "rgba(0,0,0,0.0)",
           "rgba(0,0,0,0.0)",
           "rgba(0,0,0,0.0)",
           "rgba(0,0,0,0.0)",
           "rgba(0,0,0,0.0)",
           "rgba(0,0,0,0.0)",
           "rgba(0,0,0,0.0)",
           "rgba(0,0,0,0.0)",
           "rgba(0,0,0,0.0)",
           "rgba(0,0,0,0.0)",
           "rgba(0,0,0,0.0)",
           "rgba(0,0,0,0.0)",
           "rgba(0,0,0,0.0)",
           "rgba(0,0,0,0.0)",
           "rgba(0,0,0,0.0)",
           "rgba(0,0,0,0.0)",
           "rgba(0,0,0,0.0)",
           "rgba(0,0,0,0.0)",
           "rgba(0,0,0,0.0)",
           "rgba(0,0,0,0.0)",
           "rgba(0,0,0,0.0)",
           "rgba(0,0,0,0.0)",
           "rgba(0,0,0,0.0)",
           "rgba(0,0,0,0.0)",
           "rgba(0,0,0,0.0)",
           "rgba(0,0,0,0.0)",
           "rgba(0,0,0,0.0)",
           "rgba(0,0,0,0.0)",
           "rgba(0,0,0,0.0)",
           "rgba(0,0,0,0.0)",
           "rgba(0,0,0,0.0)",
           "rgba(0,0,0,0.0)",
           "rgba(0,0,0,0.0)",
           "rgb(77, 175, 74)",
           "rgba(0,0,0,0.0)",
           "rgba(0,0,0,0.0)",
           "rgb(152, 78, 163)",
           "rgba(0,0,0,0.0)",
           "rgba(0,0,0,0.0)",
           "rgba(0,0,0,0.0)",
           "rgb(153, 153, 153)",
           "rgba(0,0,0,0.0)",
           "rgba(0,0,0,0.0)",
           "rgba(0,0,0,0.0)",
           "rgb(255, 127, 0)",
           "rgba(0,0,0,0.0)",
           "rgba(0,0,0,0.0)",
           "rgb(55, 126, 184)",
           "rgba(0,0,0,0.0)",
           "rgba(0,0,0,0.0)",
           "rgba(0,0,0,0.0)",
           "rgba(0,0,0,0.0)",
           "rgb(228, 26, 28)",
           "rgba(0,0,0,0.0)",
           "rgba(0,0,0,0.0)",
           "rgba(0,0,0,0.0)",
           "rgba(0,0,0,0.0)",
           "rgba(0,0,0,0.0)",
           "rgba(0,0,0,0.0)",
           "rgba(0,0,0,0.0)",
           "rgba(0,0,0,0.0)",
           "rgba(0,0,0,0.0)",
           "rgba(0,0,0,0.0)",
           "rgba(0,0,0,0.0)",
           "rgba(0,0,0,0.0)",
           "rgba(0,0,0,0.0)",
           "rgba(0,0,0,0.0)",
           "rgba(0,0,0,0.0)",
           "rgba(0,0,0,0.0)",
           "rgba(0,0,0,0.0)",
           "rgba(0,0,0,0.0)",
           "rgba(0,0,0,0.0)",
           "rgba(0,0,0,0.0)",
           "rgba(0,0,0,0.0)",
           "rgba(0,0,0,0.0)",
           "rgba(0,0,0,0.0)",
           "rgb(166, 86, 40)",
           "rgba(0,0,0,0.0)",
           "rgba(0,0,0,0.0)",
           "rgb(222, 222, 0)",
           "rgba(0,0,0,0.0)",
           "rgba(0,0,0,0.0)",
           "rgba(0,0,0,0.0)",
           "rgba(0,0,0,0.0)",
           "rgba(0,0,0,0.0)",
           "rgba(0,0,0,0.0)",
           "rgba(0,0,0,0.0)",
           "rgba(0,0,0,0.0)",
           "rgba(0,0,0,0.0)",
           "rgb(153, 153, 153)",
           "rgba(0,0,0,0.0)",
           "rgba(0,0,0,0.0)",
           "rgba(0,0,0,0.0)",
           "rgba(0,0,0,0.0)",
           "rgba(0,0,0,0.0)",
           "rgba(0,0,0,0.0)",
           "rgba(0,0,0,0.0)",
           "rgba(0,0,0,0.0)",
           "rgba(0,0,0,0.0)",
           "rgba(0,0,0,0.0)",
           "rgba(0,0,0,0.0)",
           "rgba(0,0,0,0.0)",
           "rgb(152, 78, 163)",
           "rgba(0,0,0,0.0)",
           "rgba(0,0,0,0.0)",
           "rgba(0,0,0,0.0)"
          ],
          "label": [
           "",
           "",
           "",
           "",
           "",
           "",
           "A9.9",
           "",
           "",
           "",
           "",
           "",
           "",
           "",
           "",
           "",
           "",
           "",
           "",
           "",
           "",
           "",
           "",
           "",
           "",
           "",
           "",
           "",
           "A9.6",
           "",
           "",
           "A10.1",
           "",
           "",
           "",
           "A3.0",
           "",
           "",
           "",
           "",
           "",
           "A10.7",
           "",
           "",
           "",
           "",
           "",
           "",
           "",
           "",
           "",
           "A5.9",
           "",
           "",
           "",
           "",
           "",
           "",
           "",
           "",
           "",
           "",
           "",
           "",
           "",
           "",
           "",
           "",
           "",
           "",
           "",
           "",
           "",
           "",
           "",
           "",
           "",
           "",
           "",
           "",
           "",
           "",
           "",
           "",
           "",
           "A11.2",
           "",
           "",
           "A10.0",
           "",
           "",
           "",
           "MLP 1",
           "",
           "",
           "",
           "MLP 3",
           "",
           "",
           "MLP 0",
           "",
           "",
           "",
           "",
           "Embed",
           "",
           "",
           "",
           "",
           "",
           "",
           "",
           "",
           "",
           "",
           "",
           "",
           "",
           "",
           "",
           "",
           "",
           "",
           "",
           "",
           "",
           "",
           "",
           "A11.10",
           "",
           "",
           "MLP 4",
           "",
           "",
           "",
           "",
           "",
           "",
           "",
           "",
           "",
           "A0.10",
           "",
           "",
           "",
           "",
           "",
           "",
           "",
           "",
           "",
           "",
           "",
           "",
           "Unembed",
           "",
           "",
           ""
          ],
          "line": {
           "width": 0
          }
         },
         "orientation": "v",
         "type": "sankey"
        }
       ],
       "layout": {
        "height": 1300,
        "plot_bgcolor": "blue",
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermap": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermap"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "rgb(55, 126, 184)",
           "rgb(255, 127, 0)",
           "rgb(77, 175, 74)",
           "rgb(247, 129, 191)",
           "rgb(228, 26, 28)",
           "rgb(152, 78, 163)",
           "rgb(166, 86, 40)",
           "rgb(153, 153, 153)",
           "rgb(222, 222, 0)"
          ],
          "font": {
           "color": "#2a3f5f",
           "size": 19
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "width": 800
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = draw_seq_graph(\n",
    "    model, attribution_scores, 3.5, layer_spacing=True, orientation=\"v\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
